"""
_create_forward_graph()
    Process the computation graph information generated by symbolic_trace().
    Specifically, it traverses all nodes in the graph produced by symbolic_trace(), 
    i.e., self._symbolic_traced_module.graph.nodes, and creates a detailed representation 
    
    for each node, which includes:
    1. Extracting and recording more runtime information for each node, such as the shapes 
       and data types of input and output tensors. This is achieved by adding information 
       to the meta attribute of each node using the ShapeProp class called previously.
    2. Identifying the operation type, associated module (if it is a module call operation), 
       input nodes, and output nodes for each node. This includes not only the static structure 
       of the node but also more detailed information from the dynamic execution process.
    3. Constructing a node engineering object, i.e., creating a detailed representation for 
       each node using a _NodeEngineer instance. This includes the node's name, operation type, 
       input and output nodes, shapes and types of input and output tensors, and data types and 
       shapes of weights and biases (if any).

_create_backward_graph()
    Traverse grad_fn (the function that generates the tensor) and their next_functions to 
    gradually build the gradient computation graph for the entire model. The key steps in this 

    process include:
    1. Registering forward hooks to collect the grad_fn of each operation's output tensor, 
       as well as their corresponding module information.
    2. Calling backward() on the output tensor to trigger the backward propagation process.
    3. During the backward propagation, recording the input and output information of each 
       gradient function grad_fn through the registered hooks, including the shapes and data 
       types of tensors.
"""

import json
import torch
import torch.fx
import sys
from torch.fx.node import Node, map_aggregate
sys.path.append('/root/Echo-workload-tracer/tracer_core/torch_analysis')
from shape_prop import ShapeProp, TensorMetadata, extract_tensor_metadata
from typename import typename
from graph_node import Node, NodeEngineer
from transformers import PreTrainedModel
from torch.fx import symbolic_trace
from transformers.utils.fx import symbolic_trace as transformers_symbolic_trace
import os
from typing import List, Optional, Dict, Any, Union
import logging
sys.setrecursionlimit(1500)


def forward_hook_fn(
    module, input, output
) -> None:
    """
    Forward hook function to set metadata for the output tensor.
    """
    if 'module' not in output.grad_fn.metadata:
        output.grad_fn.metadata['module'] = module


class TorchGraph:
    def __init__(
        self, module: torch.nn.Module, example: torch.tensor, optimizer: torch.optim, name: str, logger: Optional[logging.Logger] = None
    ) -> None:
        """
        Initialize the TorchGraph instance with a module, example input, optimizer, name, and logger.
        
        Args:
            module: PyTorch model to trace
            example: Example input tensor for the model
            optimizer: Optimizer for the model
            name: Name of the model
            logger: Logger object for logging progress (optional)
        """
        self._module = module
        self._example = example
        self.name = name
        self._optimizer = optimizer
        self._NodeEngineer = NodeEngineer()
        self.logger = logger or logging.getLogger(__name__)
        
        if isinstance(module, PreTrainedModel):
            self._symbolic_traced_module = transformers_symbolic_trace(module)
            ShapeProp(self._symbolic_traced_module).propagate(example)
        else:
            self._symbolic_traced_module = symbolic_trace(module)
            ShapeProp(self._symbolic_traced_module).propagate(example)
        self._graph_dict = {}
        self._fwd_graph_dict = {}
        # Record node for JSON file, different from _backward_graph_dict
        self._bwd_graph_dict = {} 
        self._optim_graph_dict = {}
        self._grad_fn_list = []
        self._backward_op_dict = {}
        self._backward_graph_dict = {}
        self._forward_graph = []
        self._backward_graph = []
        
        self.logger.info("Starting forward graph creation...")
        self._create_forward_graph()
        self.logger.info("Forward graph creation completed")
        
        self.logger.info("Starting backward graph creation...")
        self._create_backward_graph()
        self.logger.info("Backward graph creation completed")
        
        self.logger.info("Building optimizer representation...")
        self._build_optimizer()
        self.logger.info("Optimizer representation built successfully")

    def _get_leaf_node(
        self, target: str
    ) -> torch.nn.Module:
        """
        Get the leaf node (module) from the target string.
        """
        py_obj = self._module
        atoms = target.split(".")
        for atom in atoms:
            if not hasattr(py_obj, atom):
                raise RuntimeError(
                    str(py_obj) + " does not have attribute " + atom + "!"
                )
            py_obj = getattr(py_obj, atom)
        return py_obj

    def _get_node_name(
        self, node: torch.fx.node.Node
    ) -> str:
        """
        Get the name of the node.
        """
        return node.name

    def _get_node_op(
        self, node: torch.fx.node.Node
    ) -> str:
        """
        Get the operation type of the node.
        """
        if node.op == "call_module":
            return typename(self._get_leaf_node(node.target))
        else:
            return typename(node.target)

    def _get_node_input_nodes(
        self, node: torch.fx.node.Node
    ):
        """
        Get the input nodes of the current node.
        """
        return [node.name for node in node._input_nodes]

    def _get_node_output_nodes(
        self, node: torch.fx.node.Node
    ):
        """
        Get the output nodes of the current node.
        """
        return [node.name for node in node.users]

    def _insert_meta_obj(
        self, meta_obj
    ) -> None:
        """
        Recursively insert TensorMetadata objects into the _Metadata_list.
        """
        if isinstance(meta_obj, TensorMetadata):
            self._Metadata_list.append(meta_obj)
        else:
            if isinstance(meta_obj, dict):
                for obj in meta_obj.values():
                    self._insert_meta_obj(obj)
            elif isinstance(meta_obj, list):
                for obj in meta_obj:
                    self._insert_meta_obj(obj)

    def _get_node_input_tensor_metadata(
        self, node: torch.fx.node.Node
    ) -> List[TensorMetadata]:
        """
        Get the input tensor metadata for the given node.
        """
        self._Metadata_list = []
        for input_node in node._input_nodes.keys():
            meta_obj = input_node.meta.get("tensor_meta")
            self._insert_meta_obj(meta_obj)
        return self._Metadata_list

    def _get_node_tensor_metadata(
        self, node: torch.fx.node.Node
    ) -> List[TensorMetadata]:
        """
        Get the tensor metadata for the given node.
        """
        self._Metadata_list = []
        meta_obj = node.meta.get("tensor_meta")
        self._insert_meta_obj(meta_obj)
        return self._Metadata_list

    def _get_node_output_tensor_metadata(
        self, node: torch.fx.node.Node
    ) -> List[TensorMetadata]:
        """
        Get the output tensor metadata for the given node.
        """
        self._Metadata_list = []
        for input_node in node.users.keys():
            meta_obj = input_node.meta.get("tensor_meta")
            self._insert_meta_obj(meta_obj)
        return self._Metadata_list

    def _get_node_input_types(
        self, node: torch.fx.node.Node
    ) -> List[str]:
        """
        Get the data types of the input tensors for the given node.
        """
        return [str(Metadata.dtype) for Metadata in self._get_node_input_tensor_metadata(node)]

    def _get_node_input_shapes(
        self, node: torch.fx.node.Node
    ) -> List[torch.Size]:
        """
        Get the shapes of the input tensors for the given node.
        """
        return [Metadata.shape for Metadata in self._get_node_input_tensor_metadata(node)]

    def _get_node_output_types(
        self, node: torch.fx.node.Node
    ) -> List[str]:
        """
        Get the data types of the output tensors for the given node.
        """
        return [str(Metadata.dtype) for Metadata in self._get_node_tensor_metadata(node)]

    def _get_node_output_shapes(
        self, node: torch.fx.node.Node
    ) -> List[torch.Size]:
        """
        Get the shapes of the output tensors for the given node.
        """
        return [Metadata.shape for Metadata in self._get_node_tensor_metadata(node)]

    def _get_node_weight_type(
        self, node: torch.fx.node.Node
    ) -> Optional[str]:
        """
        Get the data type of the weight for the given node (if applicable).
        """
        if node.op == "call_module":
            leaf_module = self._get_leaf_node(node.target)
            if hasattr(leaf_module, "weight") and leaf_module.weight is not None:
                return str(leaf_module.weight.dtype)
        return None

    def _get_node_weight_shape(
        self, node: torch.fx.node.Node
    ) -> Optional[torch.Size]:
        """
        Get the shape of the weight for the given node (if applicable).
        """
        if node.op == "call_module":
            leaf_module = self._get_leaf_node(node.target)
            if hasattr(leaf_module, "weight") and leaf_module.weight is not None:
                return leaf_module.weight.size()
        return None

    def _get_node_bias_type(
        self, node: torch.fx.node.Node
    ) -> Optional[str]:
        """
        Get the data type of the bias for the given node (if applicable).
        """
        if node.op == "call_module":
            leaf_module = self._get_leaf_node(node.target)
            if hasattr(leaf_module, "bias") and leaf_module.bias is not None:
                return str(leaf_module.bias.dtype)
        return None

    def _get_node_bias_shape(
        self, node: torch.fx.node.Node
    ) -> Optional[torch.Size]:
        """
        Get the shape of the bias for the given node (if applicable).
        """
        if node.op == "call_module":
            leaf_module = self._get_leaf_node(node.target)
            if hasattr(leaf_module, "bias") and leaf_module.bias is not None:
                return leaf_module.bias.size()
        return None

    def _get_node_attr(
        self, node: torch.fx.node.Node
    ) -> Optional[Dict[str, Any]]:
        """
        Get the attributes of the given node (if applicable).
        """
        if node.op == "call_module":
            leaf_module = self._get_leaf_node(node.target)
            attr = {}
            if hasattr(leaf_module, "__constants__"):
                for c in leaf_module.__constants__:
                    attr[c] = getattr(leaf_module, c)
            return attr
        return None

    def _create_forward_node(
        self, node: torch.fx.node.Node, op: str
    ) -> Any:
        """
        Create a forward node representation using NodeEngineer.
        """
        return self._NodeEngineer.construct_node(
            name=self._get_node_name(node),
            op=self._get_node_op(node),
            input_nodes=self._get_node_input_nodes(node),
            output_nodes=self._get_node_output_nodes(node),
            input_types=self._get_node_input_types(node),
            input_shapes=self._get_node_input_shapes(node),
            output_types=self._get_node_output_types(node),
            output_shapes=self._get_node_output_shapes(node),
            weight_type=self._get_node_weight_type(node),
            weight_shape=self._get_node_weight_shape(node),
            bias_type=self._get_node_bias_type(node),
            bias_shape=self._get_node_bias_shape(node),
            attrs=self._get_node_attr(node)
        )

    def _create_forward_graph(
        self
    ) -> None:
        """
        Create the forward graph representation.
        """
        node_count = 0
        for node in self._symbolic_traced_module.graph.nodes:
            forward_node = self._create_forward_node(node, self._get_node_op(node))
            self._forward_graph.append(forward_node)
            self._graph_dict[forward_node.name] = forward_node
            self._fwd_graph_dict[forward_node.name] = forward_node
            node_count += 1
        
        self.logger.info(f"Created forward graph with {node_count} nodes")

    def _get_bp_node_attr(
        self, node: torch.fx.node.Node
    ) -> Optional[Dict[str, Any]]:
        """
        Get the attributes of the given backward node (if applicable).
        """
        if 'module' in node.metadata:
            attr = {}
            if hasattr(node.metadata['module'], "__constants__"):
                for c in node.metadata['module'].__constants__:
                    attr[c] = getattr(node.metadata['module'], c)
            return attr
        return None

    def _get_bp_node_name(
        self, node
    ) -> str:
        """
        Get the name of the given backward node.
        """
        return self._backward_graph_dict[node]['name']

    def _get_bp_node_op(
        self, node
    ) -> str:
        """
        Get the operation type of the given backward node.
        """
        return type(node).__name__

    def _get_bp_node_input_nodes(
        self, node
    ) -> List[str]:
        """
        Get the input nodes of the given backward node.
        """
        return [self._backward_graph_dict[node]['name'] 
                for node in self._backward_graph_dict[node]['input_nodes']]

    def _get_bp_node_output_nodes(
        self, node
    ) -> List[str]:
        """
        Get the output nodes of the given backward node.
        """
        return [self._backward_graph_dict[node]['name'] 
                for node in self._backward_graph_dict[node]['output_nodes']]

    def _get_tensor_meta(
        self, result
    ) -> Any:
        """
        Extract tensor metadata from the result.
        """
        def extract_tensor_meta(obj):
            if isinstance(obj, torch.Tensor):
                return extract_tensor_metadata(obj)
            else:
                return obj

        meta = map_aggregate(result, extract_tensor_meta)
        return meta

    def _get_bp_node_input_types(
        self, node
    ) -> List[str]:
        """
        Get the data types of the input tensors for the given backward node.
        """
        return [str(Metadata.dtype) if Metadata else Metadata 
                for Metadata in self._backward_graph_dict[node]['input_meta']]

    def _get_bp_node_input_shapes(
        self, node
    ) -> List[torch.Size]:
        """
        Get the shapes of the input tensors for the given backward node.
        """
        return [(Metadata.shape) if Metadata else Metadata 
                for Metadata in self._backward_graph_dict[node]['input_meta']]

    def _get_bp_node_output_types(
        self, node
    ) -> List[str]:
        """
        Get the data types of the output tensors for the given backward node.
        """
        return [str(Metadata.dtype) if Metadata else Metadata 
                for Metadata in self._backward_graph_dict[node]['output_meta']]

    def _get_bp_node_output_shapes(
        self, node
    ) -> List[torch.Size]:
        """
        Get the shapes of the output tensors for the given backward node.
        """
        return [(Metadata.shape) if Metadata else Metadata 
                for Metadata in self._backward_graph_dict[node]['output_meta']]

    def _make_forward_hook(
        self
    ):
            def hook(
                module, input, output
            ):
                try:
                    if 'module' not in output.grad_fn.metadata:
                        output.grad_fn.metadata['module'] = module
                except Exception as e:
                    print(f"An exception occurred while setting metadata: {e}")
            return hook

    def _record_grad_fn(
        self, grad_fn
    ) -> None:
        """
        Record the grad_fn in the backward graph dictionary.
        """
        self._backward_graph_dict[grad_fn] = {
            'input_nodes': [],
            'output_nodes': []
        }


    def _insert_tensor_obj(
        self, tensor_obj
    ) -> None:
        """
        Recursively insert tensor objects into the _output_list.
        """
        if isinstance(tensor_obj, torch.Tensor):
            self._output_list.append(tensor_obj)
        else:
            if isinstance(tensor_obj, dict):
                for obj in tensor_obj.values():
                    self._insert_tensor_obj(obj)
            else:
                for obj in tensor_obj:
                    self._insert_tensor_obj(obj)

    def _make_backward_hook(self, node):
        def hook(inputs, outputs):
            if self._get_bp_node_op(node) not in self._backward_op_dict:
                self._backward_op_dict[self._get_bp_node_op(node)] = 0
            else:
                self._backward_op_dict[self._get_bp_node_op(node)] += 1
            self._backward_graph_dict[node]['name'] = \
                self._get_bp_node_op(node) +str(self._backward_op_dict[self._get_bp_node_op(node)])

            self._backward_graph_dict[node]['input_meta'] = \
                self._get_tensor_meta(outputs)
            self._backward_graph_dict[node]['output_meta'] = \
                self._get_tensor_meta(inputs)

            self._grad_fn_list.append(node)
        return hook

    def _register_hook(
        self, var
    ) -> None:
        """
        Register hooks for the given variable.
        """
        self._output_list = []
        self._insert_tensor_obj(var) 
        BFS_list = []

        var = self._output_list[0]
        self._record_grad_fn(var.grad_fn)

        BFS_list.append(var.grad_fn)

        while BFS_list:
            grad_fn = BFS_list[0]
            BFS_list.pop(0)
            grad_fn.register_hook(self._make_backward_hook(grad_fn))
            if hasattr(grad_fn, 'next_functions'):
                for u in grad_fn.next_functions:
                    if u[0] is not None:
                        if u[0] not in self._backward_graph_dict:
                            BFS_list.append(u[0])
                            self._record_grad_fn(u[0])
                        self._backward_graph_dict[grad_fn]['output_nodes'].append(u[0])
                        self._backward_graph_dict[u[0]]['input_nodes'].append(grad_fn)
        try:
            var.backward()
        except:
            var.backward(var)

        for node in self._grad_fn_list:
            backward_node = self._NodeEngineer.construct_node(
                name=self._get_bp_node_name(node),
                op=self._get_bp_node_op(node),
                input_nodes=self._get_bp_node_input_nodes(node),
                output_nodes=self._get_bp_node_output_nodes(node),
                input_types=self._get_bp_node_input_types(node),
                input_shapes=self._get_bp_node_input_shapes(node),
                output_types=self._get_bp_node_output_types(node),
                output_shapes=self._get_bp_node_output_shapes(node),
                attrs=self._get_bp_node_attr(node),
            )

            if node == var.grad_fn:
                # bwd_graph need additional ouput node (last node from fwd graph) as input node
                self._graph_dict['output'].output_nodes.append(backward_node.name)
                backward_node.input_nodes.append('output')

            self._backward_graph.append(backward_node)
            self._graph_dict[backward_node.name] = backward_node


    def _make_forward_hook(
        self
    ) -> Any:
        """
        Create a forward hook for the module.
        """
        def hook(module, input, output):
            try:
                if 'module' not in output.grad_fn.metadata:
                    output.grad_fn.metadata['module'] = module
            except Exception as e:
                print(f"An exception occurred while setting metadata: {e}")
        return hook


    def _create_backward_graph(
        self
    ) -> None:
        """
        Create the backward graph representation.
        """
        for m in self._module.modules():
            if not m._modules:
                m.register_forward_hook(self._make_forward_hook())

        output_example = self._module(self._example)
        if isinstance(self._module, PreTrainedModel):
            if isinstance(output_example, tuple):
                output_example = output_example[0]  # adjust this as needed
            if hasattr(output_example, 'pooler_output'):
                output_example = output_example.pooler_output
            elif hasattr(output_example, 'last_hidden_state'):
                output_example = output_example.last_hidden_state
        
        self._register_hook(output_example)
        self.logger.info(f"Created backward graph with {len(self._backward_graph)} nodes")


    def _build_optimizer(
        self
    ) -> None:
        """
        Build the optimizer representation.
        """
        self._optimizer_params_type = []
        self._optimizer_params_shape = []
        param_count = 0
        for group in self._optimizer.param_groups:
            for p in group['params']:
                self._optimizer_params_type.append(str(p.dtype))
                self._optimizer_params_shape.append((p.shape))
                param_count += 1
        
        self.logger.info(f"Optimizer includes {param_count} parameters")

        Optimizer_zero = self._NodeEngineer.construct_node(
            name="optimizer_zero",
            op="optimizer_zero",
            input_nodes=[],
            output_nodes=[],
            input_types=self._optimizer_params_type,
            input_shapes=self._optimizer_params_shape,
            output_types=[],
            output_shapes=[],
            attrs=self._optimizer.defaults
        )

        Optimizer_step = self._NodeEngineer.construct_node(
            name="optimizer_step",
            op="optimizer_step",
            input_nodes=[],
            output_nodes=[],
            input_types=self._optimizer_params_type,
            input_shapes=self._optimizer_params_shape,
            output_types=[],
            output_shapes=[],
            attrs=self._optimizer.defaults
        )

        # TODO: The graph dict currently does not include optimizer operators?
        for item in self._graph_dict.values():
            if item.input_nodes == []:
                Optimizer_zero.output_nodes.append(item.name)
        
        for item in self._graph_dict.values():
            if item.output_nodes == []:
                Optimizer_step.input_nodes.append(item.name)

        self._optim_graph_dict['optimizer_zero'] = Optimizer_zero
        self._optim_graph_dict['optimizer_step'] = Optimizer_step
        
        # TODO: The graph dict currently does not include optimizer operators?
        # self._graph_dict['optimizer_zero'] = Optimizer_zero
        # self._graph_dict['optimizer_step'] = Optimizer_step
        
    def get_forward_graph(
        self
    ) -> Any:
        """
        Get the forward graph representation.
        """
        return self._forward_graph


    def get_backward_graph(
        self
    ) -> Any:
        """
        Get the backward graph representation.
        """
        return self._backward_graph


    def get_output_json(
        self
    ) -> List[Dict[str, Any]]:
        """
        Get the JSON representation of the entire graph.
        """
        return [item.to_json() for item in self._graph_dict.values()]


    def get_fwd_output_json(
        self
    ) -> List[Dict[str, Any]]:
        """
        Get the JSON representation of the forward graph.
        """
        del self._fwd_graph_dict['output']
        return [item.to_json() for item in self._fwd_graph_dict.values()]


    def get_bwd_output_json(
        self
    ) -> List[Dict[str, Any]]:
        """
        Get the JSON representation of the backward graph.
        """
        self._bwd_graph_dict = {
            key: value
            for key, value in self._graph_dict.items()
            if key not in self._fwd_graph_dict
        }
        return [item.to_json() for item in self._bwd_graph_dict.values()]


    def get_optim_output_json(
        self
    ) -> List[Dict[str, Any]]:
        """
        Get the JSON representation of the optimizer graph.
        """
        return [item.to_json() for item in self._optim_graph_dict.values()]


    def dump_graph(
        self, path: str
    ) -> None:
        """
        Dump the entire graph to a JSON file.
        """
        if os.path.dirname(path):
            os.makedirs(os.path.dirname(path), exist_ok=True)
        with open(path, 'w') as file:
            json.dump(self.get_output_json(), file, indent=4)


    def dump_fwd_graph(
        self, path: str
    ) -> None:
        """
        Dump the forward graph to a JSON file.
        """
        if os.path.dirname(path):
            os.makedirs(os.path.dirname(path), exist_ok=True)
        with open(path, 'w') as file:
            json.dump(self.get_fwd_output_json(), file, indent=4)


    def dump_bwd_graph(
        self, path: str
    ) -> None:
        """
        Dump the backward graph to a JSON file.
        """
        if os.path.dirname(path):
            os.makedirs(os.path.dirname(path), exist_ok=True)
        with open(path, 'w') as file:
            json.dump(self.get_bwd_output_json(), file, indent=4)


    def dump_optim_graph(
        self, path: str
    ) -> None:
        """
        Dump the optimizer graph to a JSON file.
        """
        if os.path.dirname(path):
            os.makedirs(os.path.dirname(path), exist_ok=True)
        with open(path, 'w') as file:
            json.dump(self.get_optim_output_json(), file, indent=4)